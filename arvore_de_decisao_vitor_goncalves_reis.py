# -*- coding: utf-8 -*-
"""Arvore de Decisao-Vitor Goncalves Reis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gzaUdsI8LumhQY_s4zkTIK_qbFXnLEyR
"""

# Vitor Gonçalves Reis da Silva
# RA: 156670

import pandas as pd
import zipfile
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import balanced_accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import ConfusionMatrixDisplay

from google.colab import drive
drive.mount('/content/drive')

zf = zipfile.ZipFile('/content/drive/MyDrive/Data/Diabetes_Classificacao/diabetes-classification.zip')  #aloca o arquivo zip

data_train = pd.read_csv(zf.open('train.csv')) # abre o arquivo CSV 'train.csv' presente dentro do ZIP

data_test = pd.read_csv('/content/drive/MyDrive/Data/Diabetes_Classificacao/new_test.csv')   # abre o arquivo CSV 'new_test.csv' que foi criado após adição da coluna 'diabetes_svm'

data_train.head() # mostra o cabeçalho presentes nas amostras do conjunto de treinamento

data_train = data_train.drop('p_id', axis=1) # remove a coluna de IDs
data_train.head()

x_train = data_train.values[:,0:8] # seleciona X atributos
label_train = data_train.values[:,8] # seleciona Y

# carregar teste
x_test = data_test.values[:,0:8] # seleciona X atributos
label_test = data_test.values[:,8] #seleciona Y

data_train_shuffle=data_train.sample(frac=1)
#data_train_shuffle=data_train #serve para verificar
label_train= data_train_shuffle.values[:,8] #seleciona Y com os valores embaralhados
data_train_shuffle.head()

acuracia=np.array([0.,0.,0.,0.,0.,0.,0.,0.,0.,0.])
x_tabela=np.array([0,0,0,0,0,0,0,0,0,0])
i=0
for x in range(61,614,61):
  if x==610:
    x=x+4
  P=data_train_shuffle[:x] # atribui a P
  x_train=P.values[:,0:8] # pega os valores dos 10% , 20% , assim em diante
  label_train = P.values[:,8]
  clf = DecisionTreeClassifier(random_state=0)# treina a arvore
  clf.fit(x_train,label_train)
  _ = ConfusionMatrixDisplay.from_estimator(clf,x_test,label_test)
  predicao = clf.predict(x_test)
  acuracia[i]=balanced_accuracy_score(label_test, predicao)# adiciona os valores da acuracia no array
  x_tabela[i]=x # adiciona os valores de x no array
  i=i+1

plt.plot(x_tabela,acuracia)# X é as porcentagens 10%, 20%, 30% mas representado em quantidade e Y a acuracia
plt.show()

acuracia=np.array([0.,0.,0.,0.,0.,0.,0.,0.,0.,0.])
x_tabela=np.array([1,2,3,4,5,6,7,8,9,10]) #array para plotar o grafico


for x in range(1,11):
  clf = DecisionTreeClassifier(random_state=0, max_depth= x) #treina a arvore com diferentes profundidades
  clf.fit(x_train,label_train)
  predicao = clf.predict(x_test)
  acuracia[x-1]=balanced_accuracy_score(label_test, predicao) # adiciona os valores da acuraria no array

plt.plot(x_tabela,acuracia)# X é a profundidade e Y as acuracias conforme varia as profundidades
plt.show()